{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# Import\n",
    "import os\n",
    "import cv2\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Data\n",
    "path = 'C:\\\\Users\\\\User\\\\Desktop\\\\pjj\\\\ImgData'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Label = []\n",
    "numLabel = 2\n",
    "for i in range(numLabel):\n",
    "    subLabel = [0]*numLabel\n",
    "    subLabel[i] = 1\n",
    "    Label.append(subLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0], [0, 1]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2710ee3a8d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAG4AAAD8CAYAAACW9ZGzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAGYpJREFUeJztXX2MXNV1/533ZmZnZz+967XX3nXAwcaOQwqhCKhQJQdKRWgDqJAoJCKJRBpVaqpEoQ2kyR8NbVWiNrRSS2ndJg1VCV8hKDSNCB8hCdCG8E1MjD8wYJa1vTbrtXd3dne+bv+YYe45Z3dm3oztN772/Umrvffd+967u+fdc+49X5eMMfBwD0G7B+DRGjzhHIUnnKPwhHMUnnCOwhPOUXjCOQpPOEdxVIQjosuIaDsR7SKim47VoDwag1rVnBBRCGAHgEsBjAF4BsC1xphf17on0dllkn0DLb1PQA9ZfX6JOduBCrJzodN2LvWW5H1hUfadSdrnyK6Lh8TGsKgv1b/3XeQPT6KQnY3UOxHtkUvifAC7jDG7AYCI7gZwJYCahEv2DWDdJ79UrRs2RFLEMEHtepCXbaWUrA9sK1TLHQcXRNvkWZlq+cgls6JtqH9G1A89NVwth/PyHfrjKXbasu5rwtr38rY3vnUrouJoWOUIgLdYfaxyTYCIPkdEzxLRs8XsrG72aBFHQ7ilpvQivmuM2WKMOc8Yc16Y6TqK13lwHA2rHAOwhtVHAYzXu8EEQK7X1lNHbHkR+1Mj42y1lJRtow9NijotWFZJ85JVrhy3fYeelh/S/DeljJsbsc/pfVUOiMtRAJjrtAPU46vHKhvJzlo4mhn3DID1RLSWiFIAPg7gwaN4nkcTaHnGGWMKRPR5AD8GEAL4tjHmlWM2Mo+6OBpWCWPMjwD8KGp/Kkn2SJYTCVa4FLr2WZ4y8Nw78rlzkh2aDrvMNCnJt6gg2SHHbE4uTzefs61afnrsA7IzyQEXU5b/JdWKXrN9MNYZZmsOpy685sRReMI5Ck84R3FUMq5ZUAkImDjiy2S9hNbbg8En7U6j1JsRbbPrhkU986YVpFSUy/ZSpsO+PyG/24O7+0S9OLDfPnOvfE6oxpdkSpeFftmmtUKJaSyNJrSPfsY5Ck84R+EJ5yhilXEgiE8lMc+Yuta+11EFBdNzot4xma7Z16j9FpdrJpTf7YZ/Oyzqb/3PBvtOKUZR0K/kKrk66jrdTrW3lXXhZ5yj8IRzFLGySoPabEJryVOz2rJq61ylBQCTmzpFffBX9mFBNifaKF+bNwWHpb0wlbHvOXKa/FeVQqXyYqwzqcyOxdqcHIFnlacWPOEchSeco4hX5WWAgIscU6MMYNkL0nTDUerukBfUvWMf6q6WR34mBU44Y3VuwZzSWy1IechRyEiZFkhLElLTdhDFDtmXm6+AxSqwVuBnnKPwhHMUsWtOhOMM02oEynGVZqR2BIHtu/vqXtE0+MEJUTcF+5I3M4Oi7Yy7rYrGJKUXD4WyHry8q1oOP3g26mFuuR1fQg09VGyVa1mKyic0KvyMcxSecI7CE85RxCvjIJfC3OptAqVCL8g1dPZs63u79oK3RNtQp/T5ny/aP2vrBrl1yJ5u5WPX8/I5UB5hwZCVj8Pf2yXaDl6+TtSpZP8wvXXQsQ0hs4oEedu3mW2Cn3GOwhPOUXjCOYp4zTok5RpXBS3i70re5HrtHqsnIeVfb1Kaz4/krZtVJi3VWPvO76mWz9iqXMv0eLP2uZSWsjLMqYDJTO2gj0Bp0gwzCQkLuJdxJz8aEo6Ivk1EE0S0lV0bIKJHiGhn5fey4ztMD40orPI7AP4JwH+yazcBeMwYc0slaP8mADc2+3JpAZd8wmSk2Xhu0LIXzRoDxWNSgWWl3R2STx1ZZ/VRRrE/ysrnCvaotitde+VzJ99v+ybl7gT5blnnKjFu+dfh0/XQsKsx5ucAJtXlKwHcUSnfAeCq6K/0OBZoVcatNMbsBYDK7xW1OvoY8OOD47448THgxwetbgf2E9EqY8xeIloFYKLhHSgv+blcCxeY1ThdP7KRm0Y6ArkdWFAeqAHbWxx+aJVo62LicPZMuW7v+sXrNd9PSuamJpQgM1bGNYrr5tsFHdwSFa3OuAcBfLpS/jSAH7T4HI8WEWU7cBeA/wOwgYjGiOh6ALcAuJSIdqKcWeiW4ztMD42GrNIYc22NpkuO8Vg8mkC8Zh0DBPml9Tp6HwcVZN+/0+6xEsr99xfjp4v6+sED1XLnpVL8dn3TBi8mp9S+TQWB1M1zduCQqA782uYo0+4Is6t1oD97B2+KmPML8CovZ+EJ5yhitw5wZ1Hu8aVjtako19TBEy9Uy8/962+JttKg5DHDH91dLb/89mrRNvt5q2+aOSRjyTf885B855s2BtxkdQCfxLJHX6uW9/+Bso4rjptmeqh55oTWKNeLGFv0rh4nEjzhHIUnnKOIPehDqLmYvAtVYISOzw6HrPxZ/SmpmkopFViJratVCDjOW2U9u/b0SDNidkQGene/qf+CaMhMSPmc65Ee0tzM42PATzF4wjmK2B1iefoKzjYVt0NhhQzsSM7Y/IDvyUitRUmpHGYKVjVRyEk29bPt66vl9aNSqzLXKb9jbhFotB0gFpfe8+Ru0Ta5cb2oF7rt35067B1iTyl4wjkKTzhHEbuM45CBHpLBZ4elB1bvDrtunitKy/ULE/K4g9W9Nu1haVql9u2ywnRsSqY5TKyS3zHfLGgLOJRKzrD4cepRLhpqSxLkWEAnt4B7GXfywxPOUXjCOYq2pj0MWOCE9owqdErBwGXM48+8V7QFgzI6fuOg3Z9t2Pi2aNvzk9PsOz4gN48pFWQvvKknZUpEaIs9v29a+o8WOlVa4AX2t9XJ9VIPfsY5Ck84RxG7sxA/iI8HOeisqotygzBsvFmqlNL3y/atB6yWf/OojN3e1W9jyYtTcsux7r/3yOHmWGBHHdYIANRlUy+aThVMUqpt2haBL3XfIOFnnKPwhHMUnnCOIn6VF2Pk3JRTUofjLcp7wh/RJVP5zl8tk2ed/j1r9tlxREaABaPWPBTukqop06vqZE3VtL92GkYAMLNsDLMqmRek9xiX7dy0VS/zu4afcY4iStDHGiJ6nIi2EdErRPSFynUfB95GRJlxBQA3GGPeB+BCAH9MRJtg48DXA3isUveICVGidfYCeDdseJqItqF8bPSVADZXut0B4KeIEMDPXReE97IaiQ6c4IH2+sBabXIpXGPdDJb/QLocFIfstzr5E2V+KUkhQwenUAulUSU7x6yabeaitfI5Wnbxw95bTPPblIwjotMBfBDA02giDtzj2CMy4YioG8D9AL5ojDnSqD+7rxq8X5jzwfvHCpG2A0SURJlodxpjvl+5HCkO3BizBcAWAMisWFOTMehYaHFgEgCTtpZs0yn5KM2p0zxY+ZU7pYfV/HL2Tpn1FzStTpqt4+XFWSMAUMLuZ/QpIDp/SatOsOL9jToQEQH4FoBtxphbWZOPA28josy4iwBcB+BXRPRi5dqfoxz3fW8lJnwPgI8enyF6LIUoq8onUVtx7ePA24TYVV4B2wI0E8jHozf0obRIK08utl1YtlPKvz1r7Z8cFOqnEzYLdh1fPEPmS8n1S9NNkLd9syuUR7TaDnB5LuSfD2w8+eEJ5yg84RxF/NE6XN3DeLretyWzsr79i9aUs26LlEW5ldLMk2H7ukPr5J6vNGT3Y30DKh+XOgkSTM2W2CfVX1Prpfc0P2Jm0WlWat8W5mq0eS+vkx+ecI6irYGNPD2UsAQDSM5K/pJI2zX0woC0BiRnVFQkQ3ZEPvfS922rlnPKtWx/VgV2MDVXQW0Hklm5xp8ZsSqvpDqYV5/8wT3Y+IGBzRx062eco/CEcxSecI4idk/msEbaQ83f55fJoQ3dH7I2+b2NXSLrG2635fQBKV+GUnYL8PyhNaLtnIfHRP3Jr1/IniNVZ1omJ5hcC5WJSntlh/Mtmr0Z/IxzFJ5wjiL2+Di+Ak/M8fg4lfZQmQ76fzleLZ//4Gui7d67N4t6qddqUj7ymSdE20DCuk98ZuQp0TaWkybxw6fbwRZTKnus+uT5kr/rdbk9KXZIb1++BRCHK3nNyckPTzhH4QnnKOLPgs4P+xMnOakDYdXIprfYC6MpeUbTpz7xiKj/8NWLq+W+hPTcWp6wnoV5I1/SoVzN+BjmVPpgfTJJcoZZ9tXYu8eUSo7d+s4ma70vSpFbF37GOQpPOEfhCecoYt/H8f0P36ppjy+dv3J868pqef8qmYNL4+DZdt80lJgWbVyuHS5KT61MIHVTM2ewkx9fl/+qgjS6Y9l223d2WPZdtk3K2YXl9r1CHnovr5MfnnCOoq1pD7lFQJ+rPTssv6mPXWzXyqHyMM2og7Y7z7Xx2jm1Ng9ZoPXKpHQA2jEvrdzdu+29iw6eVWwtnGfOs5IDo5SWKq/JjWxMccTHeZw4iBKtkyaiXxLRS5UY8K9Xrq8loqcrMeD3EFGq0bM8jh2izLgFABcbY84GcA6Ay4joQgDfAPD3lRjwQwCuP37D9NCIEq1jALxrNk5WfgyAiwF8onL9DgB/AeB2fX898NwmWoZolVeGeZFmS3Jyr0rKdPY3bHi0Wp4qyhOrupg5WptxtKzkp23pwMtF8SJdtrN2iJ1bLoNSxDtaFFaRbiOisBIbNwHgEQCvAZgyxry7eRlDOaDfIyZEIpwxpmiMOQfAKIDzAbxvqW5L3etjwI8PmpqoxpgplNNiXAign4jeZWijAMZr3FM9wD3R6Q9wP1ZoKOOIaAhA3hgzRUSdAH4H5YXJ4wCuAXA3osaAG2nK4eV8l3YNkHKCm3IClfRq3kiZ94//flW1/KnP/Fi0lZhQWZmU6XpnS2oDxqA9tToPyHqu2z63pERadkgnKmPlZoI7GaJswFcBuIOIQpRn6L3GmB8S0a8B3E1EfwXgBZQD/D1iQpRV5csoJ6XR13ejLO882oC2Wge4yivXLXnGhz/7pKiP52yOt56w/slSX/3Du6rlIyWpxu8P7QIpq1hjmuR2YPPVz1XLT9z5m/IlisXxLYBWeSXUmmxRiqgW4FVejsITzlF4wjmK2M06pYSVBaWQxU0rFXW3Wn/nmf5pb05awPsSMpVuwIRIbyDb5tlavSeQsnI8L3OlrsvYA9wfl5qzReqGBJNr9dIcAou3C63AzzhH4QnnKDzhHEWsMs4EQJHFxxth1pEbo9UpaarpD62n1FAo85zeM3lBzXdqk0+KJRZ5p9gt2g4WZH2EjUGJUeR6ZF14rwW12xbBuy6cWvCEcxRt9fIqpvixH/X78mX8n2y7VrRdtmabqJ+WOlgtaydX7iGmWWVR8bSJvD1EXi/hjVb4s3S+OgUUDwgBgFxf7b5R4Weco/CEcxSecI4iVhlHpnZa2+S0kgPKA3mIBSTe+v77RNuj0+8X9TR7SZqke9Y0M/OUGrhYvTVvVWCzoyq32Iy8N8/MUkllxqmXwpjLzmZSHfsZ5yg84RxFvJoTklYAHp6dnJOsUlujQ6ZiOFKS6Qk/3PuSqL9dsCxuQOVnejZrzxAvKTN2Uq3NeVrEvtOkY1F2q7Qk5Prs+Lrk0eN1txKCPXpWefLDE85ReMI5ivi9vGrEPItDAAF0qQAM7gTbr6zjWjZ1MTWX9uRaYANYnpBZ0PcsDKh32jGdu1KmRHz8LWmFD2ftHOiclAHs0yPq38zTdyVaMw/4GecoPOEchSeco4jdrFPLi1df/7vXLhX1vznzgWp5Xm2MerXMg5V54wW538qzaEodvP/yzKio9yftRvO9KsrjqckPiLrQnqm/ZZFmjYk1KrYW9dHMGakhEb1ARD+s1H0MeBvRDKv8AgBusfQx4G1E1MNtRwH8HoC/BvClyrmpTceAG5IBEeKAJCOXxT03S+s0/ssWU2r5f/UDXxD12674j2p5x9ywaDsjbQ+lPVDoFW1DKZk+ahlT888UpZotnFMH2PLUJQnVFrQYBFcHUWfcPwD4Miz3HoSPAW8rouQ5+X0AE8aY5/jlJbo2jAEvZn0M+LFC1FOJryCiywGkAfSiPAP7iShRmXV1Y8BROQc8vbr2OeAezSFKROpXAHwFAIhoM4A/NcZ8kojuQ5Mx4OneBWy8dGe1/sZd6+x7lByYXisDEpNk1UhFxShuv0JGMc8bu10ISH4rg0zN9cSRM0XbcIc03fSF1gv24YObRFtwvtxK5F6xKjAeDw4AOrScewGU+J8dU/r6G1FeqOxCWeb5GPAY0dQG3BjzU5TTZfgY8DbDq7wcRawqr+HUYXx59KFq/ZMXfbZa7nxQCoIffeNWUe8ObPtMSabKnTZSx/QD5vV1Vqc0x2xnOSnXpGUa/NUqQITn+iqUpOsyKdkZ5FjApnJV0HnAeg7Y8R5Z29rc8TPOUXjCOYpYWWUAgzRb1n/pXJue8F9e+ojoy1kjAOSNVXP1BlL91K3W0X0sl0lPKAPb+GkemjVqB9n/PWQ9wkYzypLwurQkZJiBQp/MVc99q5gyUbotgp9xjsITzlF4wjmK2C3gXAX12xmr/jp83WOyn2L4maC2nbZg5Hr7I117quXbDp0r2vj2QKc5fHH2PaK+tsumwS+piAwzL7cH+W52ELs6pUQfhFtiQZABzxHsT2w8+eEJ5yjiDfoAYZ5FPKSYV801fc+LvgVI1lhiFvI/2yfTY/zt8NOizrcSZ6b3irYce3+ovHrmVF4qrll5Zuo00YaEvDcxx/+ViuepqtCs+KCPUwuecI7CE85RxCrjQhj0B/zEDvv6A0Vp8f7VQr+ob0rtq5afP7hGPljJOI4VofTc4rlNdi2sEG3aWsDznkxkZQ6oxKQ0AXDHM2VIEAfVA/Kwd576sRn4GecoPOEchSeco4hVxhVAQpb1MHm3JpRW7Zs//mlRv/XeLdXy42fdL9p0HEmJXQlUNAn3Fss0CJB8cVqqwDjOvE1a1l+/zsrdXI/ckKVmau/rRE4wv487+eEJ5yjiTQkFyY64+itvpEp9xx9Jzf0137mhWv7FZ78p2jIqwiuo8z1uX7DOQgOhdIl/dU4ebltg24HZ78vgkR5IVskxNyx5XvrV2kv+5HRrKRD9jHMUnnCOwhPOUcRs1pGeVHw7sE8dQhu+I1VKC4NWAFzwrRtEW8+bUoZwWTGlDgXtO8tatXvT8qSP4C/lYbfJfVZdNvU12Xf4IdSEVmPp+HbuTNb9NrOcK8fZevAzzlFEDSV+A8A0gCKAgjHmPCIaAHAPgNMBvAHgY8aYQ7We4XFs0cyM+5Ax5hxjzHmV+k0AHqsE7z9WqXvEhKORcVcC2Fwp34Fy+NWN9W4wIOTA9272u5lWJyuWUlJOhFnbVx80q/OIdE5aIffe++Rejb5rO9OC9hybRi1s/NpBUTdZKfO4XA1U7pK8/NMg4kWO80kfBsDDRPQcEX2ucm2lMWYvAFR+r1jqRh4DfvidFpPseyxC1Bl3kTFmnIhWAHiEiF6N+gIeA77hN9I+BvwYIRLhjDHjld8TRPQAypGo+4lolTFmLxGtAjBR9yEoB310sZS9OTbhdy4Mq84q/ixv2U9Knom0CPVURzq9Yt3nLOQad6p2rt3ET/YA5MkfNT2+GiBKuowuIup5twzgdwFsBfAgykH7QNQD3D2OGaLMuJUAHignE0ICwHeNMQ8R0TMA7iWi6wHsAfDR4zdMD40o6TJ2Azh7ievvALjkeAzKozHaepoVT0n/xKF1oo3HVANAuGDreZXmS8s0fdKUQCn66emmw24XaH6hTk/UXdYX1MG4PG3/Qj/3+Io8NK/ychWecI7CE85RtFXGcTz3uvSoMh1SaPAgd50rUptDgnwdgbMosN5C79tMsol/TxM5ucQJVt7L69SCJ5yjaCurzDDn1MQbMndJclbFXPNQaT1qxWJKSXvBhNG/Tb78ByJsARj4wSQ6JVRSHigiti8dU2bJ6w3fF72rx4kETzhH4QnnKNqQy8sy8iwTVlpNlR2RDL9z3HYIGlhbwnkmN/JKxZVgLyrId2iZZlJMWAXqG1cWcD7+3t1yP5BVns0JJrD5WH2ek1MAnnCOIv6UUDX4QaFHsrTUpEq51GvvS41J1tMxJe8N5+usq+tYB0xaBppQ3m5XjGKVpPryLUnPmGS52VVyq8Ot8LUOQmwEP+MchSeco/CEcxRtVXnxrUE4J78hnTqwc78VAMmscpbNa48wK8eoqOQdNaHGZ/fq55hOKeNGfmr1WlPru9R45GNnWZoWvo0oNXECn59xjsITzlF4wjmK2GVciW1WePD+IjWWEj/ZEXuhb6dsS05L+RPMNxEhKAbXxB5PqcfCafuvnDpTyjhTL1/XcQ768DjB4AnnKNqQ58SyoyJjm9zhFVhs5Q7nbXvHEckaE7OSNVK+tsqLq66IlI5JbUHE1qGRIy1Tj6nzkhbF70lrvlnyeiP4GecoPOEchSecoyBj4gsSJaIDAN4EsBzAwQbd48SJMp7TjDFDUTrGSrjqS4meZdkb2o4TbTxR4Fmlo/CEcxTtItyWxl1ixYk2noZoi4zzOHp4VukoYiUcEV1GRNuJaBcRtSX3FxF9m4gmiGgruzZARI8Q0c7K72XtGFsziI1wRBQCuA3AhwFsAnAtEW2K6/0M3wFwmbrmXEK5OGfc+QB2GWN2G2NyAO5GOZFbrDDG/BzApLp8JcqJ5FD5fVWsg2oBcRJuBMBbrD5WuXYiIFJCuRMJcRJuKaOFX9K2iDgJNwaAnx82CmA8xvfXw/5KIjlETSjXbsRJuGcArCeitUSUAvBxlBO5nQhwL6GcMSa2HwCXA9gB4DUAX43z3WwMdwHYCyCPMhe4HsAgyqvJnZXfA+0YWzM/XnPiKLzmxFF4wjkKTzhH4QnnKDzhHIUnnKPwhHMUnnCO4v8Bt6gCcQvhmacAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainingData = []\n",
    "for folder,dirs,files in os.walk(path):\n",
    "    for file in files:\n",
    "        pathImg = os.path.join(folder,file)\n",
    "        #print(file) \n",
    "        img = cv2.imread(pathImg,cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        img = cv2.resize(img, (20, 60)) \n",
    "        #print(folder.split('\\\\'))\n",
    "        if(folder.split('\\\\')[6] == 'People'):\n",
    "            \n",
    "            trainingData.append([img,Label[0]])\n",
    "        else:\n",
    "            trainingData.append([img,Label[1]])\n",
    "            \n",
    "shuffle(trainingData)\n",
    "#plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSize = len(trainingData) * 20 // 100\n",
    "train = trainingData[:-trainSize]\n",
    "test = trainingData[-trainSize:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImgTest = np.array([i[0] for i in test]).reshape(-1, 20 * 60) / 255\n",
    "CatTest = [i[1] for i in test]\n",
    "ImgTrain = np.array([i[0] for i in train]).reshape(-1, 20 * 60) / 255\n",
    "CatTrain = [i[1] for i in train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 1200)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(ImgTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_train():\n",
    "    \n",
    "    arr = range(748)\n",
    "    trainData = np.random.permutation(len(arr))\n",
    "    batch = []\n",
    "    cat = []\n",
    "    \n",
    "    for i in range(500):\n",
    "        batch.append(ImgTrain[trainData[i]])\n",
    "        cat.append(CatTrain[trainData[i]])\n",
    "        \n",
    "    return batch,cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-2b0d2529ca6b>:49: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-10-2b0d2529ca6b>:52: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `argmax` instead\n"
     ]
    }
   ],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x,W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 1200])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 2])\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "W = tf.Variable(tf.zeros([1200,2]))\n",
    "\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "x_image = tf.reshape(x, [-1, 20, 60, 1])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "W_fc1 = weight_variable([5 * 15 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 5 * 15 * 64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "W_fc2 = weight_variable([1024, 2])\n",
    "b_fc2 = bias_variable([2])\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_conv, labels=y_))\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.arg_max(y_conv,1), tf.arg_max(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.48\n",
      "step 1, training accuracy 0.518\n",
      "step 2, training accuracy 0.496\n",
      "step 3, training accuracy 0.498\n",
      "step 4, training accuracy 0.478\n",
      "step 5, training accuracy 0.478\n",
      "step 6, training accuracy 0.488\n",
      "step 7, training accuracy 0.582\n",
      "step 8, training accuracy 0.574\n",
      "step 9, training accuracy 0.546\n",
      "step 10, training accuracy 0.502\n",
      "step 11, training accuracy 0.524\n",
      "step 12, training accuracy 0.582\n",
      "step 13, training accuracy 0.692\n",
      "step 14, training accuracy 0.774\n",
      "step 15, training accuracy 0.716\n",
      "step 16, training accuracy 0.676\n",
      "step 17, training accuracy 0.668\n",
      "step 18, training accuracy 0.72\n",
      "step 19, training accuracy 0.738\n",
      "step 20, training accuracy 0.726\n",
      "step 21, training accuracy 0.76\n",
      "step 22, training accuracy 0.794\n",
      "step 23, training accuracy 0.774\n",
      "step 24, training accuracy 0.778\n",
      "step 25, training accuracy 0.782\n",
      "step 26, training accuracy 0.786\n",
      "step 27, training accuracy 0.778\n",
      "step 28, training accuracy 0.794\n",
      "step 29, training accuracy 0.764\n",
      "step 30, training accuracy 0.792\n",
      "step 31, training accuracy 0.788\n",
      "step 32, training accuracy 0.768\n",
      "step 33, training accuracy 0.778\n",
      "step 34, training accuracy 0.814\n",
      "step 35, training accuracy 0.782\n",
      "step 36, training accuracy 0.796\n",
      "step 37, training accuracy 0.818\n",
      "step 38, training accuracy 0.818\n",
      "step 39, training accuracy 0.82\n",
      "step 40, training accuracy 0.828\n",
      "step 41, training accuracy 0.838\n",
      "step 42, training accuracy 0.798\n",
      "step 43, training accuracy 0.818\n",
      "step 44, training accuracy 0.818\n",
      "step 45, training accuracy 0.83\n",
      "step 46, training accuracy 0.818\n",
      "step 47, training accuracy 0.826\n",
      "step 48, training accuracy 0.828\n",
      "step 49, training accuracy 0.834\n",
      "step 50, training accuracy 0.812\n",
      "step 51, training accuracy 0.828\n",
      "step 52, training accuracy 0.826\n",
      "step 53, training accuracy 0.83\n",
      "step 54, training accuracy 0.842\n",
      "step 55, training accuracy 0.83\n",
      "step 56, training accuracy 0.828\n",
      "step 57, training accuracy 0.84\n",
      "step 58, training accuracy 0.846\n",
      "step 59, training accuracy 0.826\n",
      "step 60, training accuracy 0.83\n",
      "step 61, training accuracy 0.862\n",
      "step 62, training accuracy 0.846\n",
      "step 63, training accuracy 0.844\n",
      "step 64, training accuracy 0.852\n",
      "step 65, training accuracy 0.834\n",
      "step 66, training accuracy 0.852\n",
      "step 67, training accuracy 0.86\n",
      "step 68, training accuracy 0.86\n",
      "step 69, training accuracy 0.864\n",
      "step 70, training accuracy 0.87\n",
      "step 71, training accuracy 0.85\n",
      "step 72, training accuracy 0.864\n",
      "step 73, training accuracy 0.876\n",
      "step 74, training accuracy 0.888\n",
      "step 75, training accuracy 0.878\n",
      "step 76, training accuracy 0.866\n",
      "step 77, training accuracy 0.848\n",
      "step 78, training accuracy 0.874\n",
      "step 79, training accuracy 0.868\n",
      "step 80, training accuracy 0.884\n",
      "step 81, training accuracy 0.866\n",
      "step 82, training accuracy 0.868\n",
      "step 83, training accuracy 0.88\n",
      "step 84, training accuracy 0.878\n",
      "step 85, training accuracy 0.89\n",
      "step 86, training accuracy 0.882\n",
      "step 87, training accuracy 0.898\n",
      "step 88, training accuracy 0.892\n",
      "step 89, training accuracy 0.872\n",
      "step 90, training accuracy 0.886\n",
      "step 91, training accuracy 0.894\n",
      "step 92, training accuracy 0.894\n",
      "step 93, training accuracy 0.88\n",
      "step 94, training accuracy 0.888\n",
      "step 95, training accuracy 0.888\n",
      "step 96, training accuracy 0.888\n",
      "step 97, training accuracy 0.904\n",
      "step 98, training accuracy 0.9\n",
      "step 99, training accuracy 0.894\n",
      "step 100, training accuracy 0.904\n",
      "step 101, training accuracy 0.91\n",
      "step 102, training accuracy 0.912\n",
      "step 103, training accuracy 0.904\n",
      "step 104, training accuracy 0.9\n",
      "step 105, training accuracy 0.884\n",
      "step 106, training accuracy 0.9\n",
      "step 107, training accuracy 0.894\n",
      "step 108, training accuracy 0.908\n",
      "step 109, training accuracy 0.908\n",
      "step 110, training accuracy 0.9\n",
      "step 111, training accuracy 0.902\n",
      "step 112, training accuracy 0.9\n",
      "step 113, training accuracy 0.912\n",
      "step 114, training accuracy 0.912\n",
      "step 115, training accuracy 0.908\n",
      "step 116, training accuracy 0.91\n",
      "step 117, training accuracy 0.918\n",
      "step 118, training accuracy 0.922\n",
      "step 119, training accuracy 0.926\n",
      "step 120, training accuracy 0.91\n",
      "step 121, training accuracy 0.92\n",
      "step 122, training accuracy 0.92\n",
      "step 123, training accuracy 0.92\n",
      "step 124, training accuracy 0.916\n",
      "step 125, training accuracy 0.924\n",
      "step 126, training accuracy 0.924\n",
      "step 127, training accuracy 0.932\n",
      "step 128, training accuracy 0.92\n",
      "step 129, training accuracy 0.926\n",
      "step 130, training accuracy 0.926\n",
      "step 131, training accuracy 0.93\n",
      "step 132, training accuracy 0.934\n",
      "step 133, training accuracy 0.912\n",
      "step 134, training accuracy 0.936\n",
      "step 135, training accuracy 0.924\n",
      "step 136, training accuracy 0.916\n",
      "step 137, training accuracy 0.928\n",
      "step 138, training accuracy 0.926\n",
      "step 139, training accuracy 0.928\n",
      "step 140, training accuracy 0.934\n",
      "step 141, training accuracy 0.93\n",
      "step 142, training accuracy 0.944\n",
      "step 143, training accuracy 0.926\n",
      "step 144, training accuracy 0.92\n",
      "step 145, training accuracy 0.932\n",
      "step 146, training accuracy 0.942\n",
      "step 147, training accuracy 0.932\n",
      "step 148, training accuracy 0.938\n",
      "step 149, training accuracy 0.926\n",
      "step 150, training accuracy 0.936\n",
      "step 151, training accuracy 0.94\n",
      "step 152, training accuracy 0.932\n",
      "step 153, training accuracy 0.952\n",
      "step 154, training accuracy 0.956\n",
      "step 155, training accuracy 0.948\n",
      "step 156, training accuracy 0.948\n",
      "step 157, training accuracy 0.936\n",
      "step 158, training accuracy 0.958\n",
      "step 159, training accuracy 0.94\n",
      "step 160, training accuracy 0.954\n",
      "step 161, training accuracy 0.962\n",
      "step 162, training accuracy 0.952\n",
      "step 163, training accuracy 0.954\n",
      "step 164, training accuracy 0.942\n",
      "step 165, training accuracy 0.954\n",
      "step 166, training accuracy 0.958\n",
      "step 167, training accuracy 0.958\n",
      "step 168, training accuracy 0.948\n",
      "step 169, training accuracy 0.946\n",
      "step 170, training accuracy 0.948\n",
      "step 171, training accuracy 0.96\n",
      "step 172, training accuracy 0.962\n",
      "step 173, training accuracy 0.97\n",
      "step 174, training accuracy 0.956\n",
      "step 175, training accuracy 0.954\n",
      "step 176, training accuracy 0.956\n",
      "step 177, training accuracy 0.96\n",
      "step 178, training accuracy 0.966\n",
      "step 179, training accuracy 0.974\n",
      "step 180, training accuracy 0.96\n",
      "step 181, training accuracy 0.974\n",
      "step 182, training accuracy 0.964\n",
      "step 183, training accuracy 0.974\n",
      "step 184, training accuracy 0.956\n",
      "step 185, training accuracy 0.968\n",
      "step 186, training accuracy 0.966\n",
      "step 187, training accuracy 0.972\n",
      "step 188, training accuracy 0.976\n",
      "step 189, training accuracy 0.978\n",
      "step 190, training accuracy 0.97\n",
      "step 191, training accuracy 0.972\n",
      "step 192, training accuracy 0.972\n",
      "step 193, training accuracy 0.978\n",
      "step 194, training accuracy 0.968\n",
      "step 195, training accuracy 0.974\n",
      "step 196, training accuracy 0.97\n",
      "step 197, training accuracy 0.976\n",
      "step 198, training accuracy 0.974\n",
      "step 199, training accuracy 0.978\n",
      "step 200, training accuracy 0.98\n",
      "step 201, training accuracy 0.982\n",
      "step 202, training accuracy 0.972\n",
      "step 203, training accuracy 0.972\n",
      "step 204, training accuracy 0.972\n",
      "step 205, training accuracy 0.966\n",
      "step 206, training accuracy 0.98\n",
      "step 207, training accuracy 0.982\n",
      "step 208, training accuracy 0.974\n",
      "step 209, training accuracy 0.978\n",
      "step 210, training accuracy 0.984\n",
      "step 211, training accuracy 0.984\n",
      "step 212, training accuracy 0.98\n",
      "step 213, training accuracy 0.982\n",
      "step 214, training accuracy 0.974\n",
      "step 215, training accuracy 0.98\n",
      "step 216, training accuracy 0.98\n",
      "step 217, training accuracy 0.978\n",
      "step 218, training accuracy 0.984\n",
      "step 219, training accuracy 0.984\n",
      "step 220, training accuracy 0.986\n",
      "step 221, training accuracy 0.986\n",
      "step 222, training accuracy 0.98\n",
      "step 223, training accuracy 0.98\n",
      "step 224, training accuracy 0.99\n",
      "step 225, training accuracy 0.984\n",
      "step 226, training accuracy 0.988\n",
      "step 227, training accuracy 0.99\n",
      "step 228, training accuracy 0.988\n",
      "step 229, training accuracy 0.988\n",
      "step 230, training accuracy 0.986\n",
      "step 231, training accuracy 0.986\n",
      "step 232, training accuracy 0.984\n",
      "step 233, training accuracy 0.984\n",
      "step 234, training accuracy 0.988\n",
      "step 235, training accuracy 0.99\n",
      "step 236, training accuracy 0.986\n",
      "step 237, training accuracy 0.992\n",
      "step 238, training accuracy 0.99\n",
      "step 239, training accuracy 0.99\n",
      "step 240, training accuracy 0.99\n",
      "step 241, training accuracy 0.994\n",
      "step 242, training accuracy 0.988\n",
      "step 243, training accuracy 0.992\n",
      "step 244, training accuracy 0.992\n",
      "step 245, training accuracy 0.994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 246, training accuracy 0.992\n",
      "step 247, training accuracy 0.988\n",
      "step 248, training accuracy 0.99\n",
      "step 249, training accuracy 0.988\n",
      "step 250, training accuracy 0.98\n",
      "step 251, training accuracy 0.99\n",
      "step 252, training accuracy 0.992\n",
      "step 253, training accuracy 0.99\n",
      "step 254, training accuracy 0.984\n",
      "step 255, training accuracy 0.992\n",
      "step 256, training accuracy 0.986\n",
      "step 257, training accuracy 0.992\n",
      "step 258, training accuracy 0.992\n",
      "step 259, training accuracy 0.992\n",
      "step 260, training accuracy 0.994\n",
      "step 261, training accuracy 0.986\n",
      "step 262, training accuracy 0.99\n",
      "step 263, training accuracy 0.994\n",
      "step 264, training accuracy 0.99\n",
      "step 265, training accuracy 0.988\n",
      "step 266, training accuracy 0.992\n",
      "step 267, training accuracy 0.992\n",
      "step 268, training accuracy 0.99\n",
      "step 269, training accuracy 0.992\n",
      "step 270, training accuracy 0.99\n",
      "step 271, training accuracy 0.99\n",
      "step 272, training accuracy 0.994\n",
      "step 273, training accuracy 0.998\n",
      "step 274, training accuracy 0.994\n",
      "step 275, training accuracy 0.992\n",
      "step 276, training accuracy 0.996\n",
      "step 277, training accuracy 0.996\n",
      "step 278, training accuracy 0.992\n",
      "step 279, training accuracy 0.992\n",
      "step 280, training accuracy 0.994\n",
      "step 281, training accuracy 0.994\n",
      "step 282, training accuracy 0.992\n",
      "step 283, training accuracy 0.994\n",
      "step 284, training accuracy 0.994\n",
      "step 285, training accuracy 0.994\n",
      "step 286, training accuracy 0.994\n",
      "step 287, training accuracy 0.998\n",
      "step 288, training accuracy 0.996\n",
      "step 289, training accuracy 0.996\n",
      "step 290, training accuracy 0.992\n",
      "step 291, training accuracy 0.992\n",
      "step 292, training accuracy 0.994\n",
      "step 293, training accuracy 0.998\n",
      "step 294, training accuracy 0.994\n",
      "step 295, training accuracy 0.994\n",
      "step 296, training accuracy 0.998\n",
      "step 297, training accuracy 1\n",
      "step 298, training accuracy 1\n",
      "step 299, training accuracy 0.998\n",
      "step 300, training accuracy 1\n",
      "step 301, training accuracy 0.996\n",
      "step 302, training accuracy 0.994\n",
      "step 303, training accuracy 0.992\n",
      "step 304, training accuracy 0.992\n",
      "step 305, training accuracy 0.996\n",
      "step 306, training accuracy 1\n",
      "step 307, training accuracy 0.996\n",
      "step 308, training accuracy 0.996\n",
      "step 309, training accuracy 0.998\n",
      "step 310, training accuracy 0.998\n",
      "step 311, training accuracy 0.998\n",
      "step 312, training accuracy 0.998\n",
      "step 313, training accuracy 1\n",
      "step 314, training accuracy 0.998\n",
      "step 315, training accuracy 0.998\n",
      "step 316, training accuracy 0.998\n",
      "step 317, training accuracy 0.994\n",
      "step 318, training accuracy 0.996\n",
      "step 319, training accuracy 0.998\n",
      "step 320, training accuracy 0.998\n",
      "step 321, training accuracy 0.998\n",
      "step 322, training accuracy 0.998\n",
      "step 323, training accuracy 1\n",
      "step 324, training accuracy 0.998\n",
      "step 325, training accuracy 0.998\n",
      "step 326, training accuracy 0.998\n",
      "step 327, training accuracy 0.998\n",
      "step 328, training accuracy 0.996\n",
      "step 329, training accuracy 1\n",
      "step 330, training accuracy 0.998\n",
      "step 331, training accuracy 1\n",
      "step 332, training accuracy 0.998\n",
      "step 333, training accuracy 0.998\n",
      "step 334, training accuracy 0.998\n",
      "step 335, training accuracy 1\n",
      "step 336, training accuracy 1\n",
      "step 337, training accuracy 1\n",
      "step 338, training accuracy 0.998\n",
      "step 339, training accuracy 0.996\n",
      "step 340, training accuracy 0.998\n",
      "step 341, training accuracy 0.998\n",
      "step 342, training accuracy 0.998\n",
      "step 343, training accuracy 0.998\n",
      "step 344, training accuracy 1\n",
      "step 345, training accuracy 0.998\n",
      "step 346, training accuracy 0.998\n",
      "step 347, training accuracy 0.998\n",
      "step 348, training accuracy 0.998\n",
      "step 349, training accuracy 0.998\n",
      "step 350, training accuracy 0.998\n",
      "step 351, training accuracy 0.998\n",
      "step 352, training accuracy 1\n",
      "step 353, training accuracy 0.998\n",
      "step 354, training accuracy 0.998\n",
      "step 355, training accuracy 1\n",
      "step 356, training accuracy 0.998\n",
      "step 357, training accuracy 1\n",
      "step 358, training accuracy 0.998\n",
      "step 359, training accuracy 1\n",
      "step 360, training accuracy 0.998\n",
      "step 361, training accuracy 0.998\n",
      "step 362, training accuracy 0.998\n",
      "step 363, training accuracy 1\n",
      "step 364, training accuracy 0.998\n",
      "step 365, training accuracy 0.998\n",
      "step 366, training accuracy 0.998\n",
      "step 367, training accuracy 0.998\n",
      "step 368, training accuracy 0.998\n",
      "step 369, training accuracy 0.998\n",
      "step 370, training accuracy 0.998\n",
      "step 371, training accuracy 0.998\n",
      "step 372, training accuracy 0.998\n",
      "step 373, training accuracy 0.998\n",
      "step 374, training accuracy 1\n",
      "step 375, training accuracy 0.998\n",
      "step 376, training accuracy 1\n",
      "step 377, training accuracy 0.998\n",
      "step 378, training accuracy 1\n",
      "step 379, training accuracy 0.998\n",
      "step 380, training accuracy 1\n",
      "step 381, training accuracy 1\n",
      "step 382, training accuracy 1\n",
      "step 383, training accuracy 0.998\n",
      "step 384, training accuracy 0.998\n",
      "step 385, training accuracy 0.998\n",
      "step 386, training accuracy 1\n",
      "step 387, training accuracy 1\n",
      "step 388, training accuracy 0.998\n",
      "step 389, training accuracy 1\n",
      "step 390, training accuracy 0.998\n",
      "step 391, training accuracy 0.998\n",
      "step 392, training accuracy 0.998\n",
      "step 393, training accuracy 0.998\n",
      "step 394, training accuracy 1\n",
      "step 395, training accuracy 1\n",
      "step 396, training accuracy 0.998\n",
      "step 397, training accuracy 1\n",
      "step 398, training accuracy 0.998\n",
      "step 399, training accuracy 0.998\n",
      "step 400, training accuracy 0.998\n",
      "step 401, training accuracy 0.998\n",
      "step 402, training accuracy 0.998\n",
      "step 403, training accuracy 1\n",
      "step 404, training accuracy 0.998\n",
      "step 405, training accuracy 0.998\n",
      "step 406, training accuracy 0.998\n",
      "step 407, training accuracy 1\n",
      "step 408, training accuracy 1\n",
      "step 409, training accuracy 1\n",
      "step 410, training accuracy 1\n",
      "step 411, training accuracy 1\n",
      "step 412, training accuracy 1\n",
      "step 413, training accuracy 1\n",
      "step 414, training accuracy 1\n",
      "step 415, training accuracy 1\n",
      "step 416, training accuracy 1\n",
      "step 417, training accuracy 1\n",
      "step 418, training accuracy 1\n",
      "step 419, training accuracy 1\n",
      "step 420, training accuracy 1\n",
      "step 421, training accuracy 1\n",
      "step 422, training accuracy 1\n",
      "step 423, training accuracy 1\n",
      "step 424, training accuracy 1\n",
      "step 425, training accuracy 1\n",
      "step 426, training accuracy 1\n",
      "step 427, training accuracy 1\n",
      "step 428, training accuracy 1\n",
      "step 429, training accuracy 1\n",
      "step 430, training accuracy 1\n",
      "step 431, training accuracy 1\n",
      "step 432, training accuracy 1\n",
      "step 433, training accuracy 0.998\n",
      "step 434, training accuracy 0.998\n",
      "step 435, training accuracy 0.998\n",
      "step 436, training accuracy 0.998\n",
      "step 437, training accuracy 1\n",
      "step 438, training accuracy 1\n",
      "step 439, training accuracy 0.998\n",
      "step 440, training accuracy 1\n",
      "step 441, training accuracy 1\n",
      "step 442, training accuracy 1\n",
      "step 443, training accuracy 1\n",
      "step 444, training accuracy 1\n",
      "step 445, training accuracy 1\n",
      "step 446, training accuracy 1\n",
      "step 447, training accuracy 1\n",
      "step 448, training accuracy 0.998\n",
      "step 449, training accuracy 0.998\n",
      "step 450, training accuracy 1\n",
      "step 451, training accuracy 1\n",
      "step 452, training accuracy 1\n",
      "step 453, training accuracy 1\n",
      "step 454, training accuracy 1\n",
      "step 455, training accuracy 1\n",
      "step 456, training accuracy 1\n",
      "step 457, training accuracy 1\n",
      "step 458, training accuracy 1\n",
      "step 459, training accuracy 1\n",
      "step 460, training accuracy 1\n",
      "step 461, training accuracy 1\n",
      "step 462, training accuracy 1\n",
      "step 463, training accuracy 1\n",
      "step 464, training accuracy 1\n",
      "step 465, training accuracy 1\n",
      "step 466, training accuracy 1\n",
      "step 467, training accuracy 1\n",
      "step 468, training accuracy 1\n",
      "step 469, training accuracy 1\n",
      "step 470, training accuracy 0.998\n",
      "step 471, training accuracy 1\n",
      "step 472, training accuracy 0.998\n",
      "step 473, training accuracy 0.998\n",
      "step 474, training accuracy 0.998\n",
      "step 475, training accuracy 1\n",
      "step 476, training accuracy 1\n",
      "step 477, training accuracy 1\n",
      "step 478, training accuracy 1\n",
      "step 479, training accuracy 1\n",
      "step 480, training accuracy 1\n",
      "step 481, training accuracy 1\n",
      "step 482, training accuracy 1\n",
      "step 483, training accuracy 1\n",
      "step 484, training accuracy 1\n",
      "step 485, training accuracy 1\n",
      "step 486, training accuracy 1\n",
      "step 487, training accuracy 1\n",
      "step 488, training accuracy 1\n",
      "step 489, training accuracy 1\n",
      "step 490, training accuracy 1\n",
      "step 491, training accuracy 1\n",
      "step 492, training accuracy 1\n",
      "step 493, training accuracy 1\n",
      "step 494, training accuracy 1\n",
      "step 495, training accuracy 1\n",
      "step 496, training accuracy 1\n",
      "step 497, training accuracy 1\n",
      "step 498, training accuracy 1\n",
      "step 499, training accuracy 1\n",
      "Model saved in file:  C:/Users/User/Desktop/pjj/Model/model_20_60.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.9\n"
     ]
    }
   ],
   "source": [
    "for i in range(500):\n",
    "    \n",
    "    train_x,train_y = get_batch_train()\n",
    "    \n",
    "    if i%1 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={\n",
    "            x: train_x, y_: train_y, keep_prob: 1.0})\n",
    "        print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "        \n",
    "    train_step.run(feed_dict={x: train_x, y_: train_y, keep_prob: 0.5})\n",
    "    \n",
    "save_path = saver.save(sess, \"C:/Users/User/Desktop/pjj/Model/model_20_60.ckpt\")\n",
    "print(\"Model saved in file: \", save_path)\n",
    "    \n",
    "\n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={\n",
    "    x: ImgTest, y_: CatTest, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
